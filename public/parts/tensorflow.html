<div class="padding">
	<h1>Multiple object detection using pre trained model in TensorFlow.js</h1>
	<p class="notsupported hidden red b">It seems, like your browser does not support access to webcam.</p>
	<p id="status">Wait for the model to load before clicking the button to enable the webcam - at which point it will become visible to use.</p>

	<section id="demos" class="invisible">

		<p>Hold some objects up close to your webcam to get a real-time classification! When ready click "enable webcam" below and accept access to the webcam when the browser asks (check the top left of your window)</p>
		
		<div id="liveView" class="camView">
			<button id="webcamButton">Enable Webcam</button>
			<button id="webcamButtonStop" class="hidden">Disable Webcam</button>
			<video id="webcam" autoplay muted width="640" height="480"></video>
		</div>
	</section>
</div>

<script>
	// Store the resulting model in the global scope of our app.
	var model = undefined;
	const status = document.getElementById('status');
	if (status)
		status.innerText = 'Loaded TensorFlow.js - version: ' + tf.version.tfjs;

	const video = document.getElementById('webcam');
	const liveView = document.getElementById('liveView');
	const demosSection = document.getElementById('demos');
	const enableWebcamButton = document.getElementById('webcamButton');
	const disableWebcamButton = document.getElementById('webcamButtonStop');
	
	// Check if webcam access is supported.
	function getUserMediaSupported() {
		return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
	}

	// If webcam supported, add event listener to button for when user
	// wants to activate it to call enableCam function which we will 
	// define in the next step.
	if (!getUserMediaSupported()) {
		const notsupported = document.querySelector('.notsupported');
		notsupported.classList.toggle('hidden');
		console.warn('getUserMedia() is not supported by your browser');
	} else
		enableWebcamButton.addEventListener('click', enableCam);

	// Enable the live webcam view and start classification.
	function enableCam(event) {
		video.classList.remove('hidden');

		// Only continue if the COCO-SSD has finished loading.
		if (!model) {
			return;
		}
		
		// Hide the button once clicked.
		event.target.classList.add('hidden');  
		
		// getUsermedia parameters to force video but not audio.
		const constraints = {
			video: true
		};

		disableWebcamButton.classList.remove('hidden');
		// Activate the webcam stream.
		navigator.mediaDevices.getUserMedia(constraints).then(function(stream) {
			video.srcObject = stream;
			video.addEventListener('loadeddata', predictWebcam);
		});
	}

	const disable_cam = function () {
		if (!video?.srcObject)
			return console.error('Nothing is streaming now!');
		
		const streams = video.srcObject.getTracks();

		if (!streams.length) {
			return console.error('Nothing is streaming now - No cameras founded!');
		}
		
		video.classList.add('hidden');
		disableWebcamButton.classList.add('hidden');
		enableWebcamButton.classList.remove('hidden');
		
		streams.forEach(track => {
			track.stop();
		});
	};

	disableWebcamButton.addEventListener('click', disable_cam);

	// Before we can use COCO-SSD class we must wait for it to finish
	// loading. Machine Learning models can be large and take a moment 
	// to get everything needed to run.
	// Note: cocoSsd is an external object loaded from our index.html
	// script tag import so ignore any warning in Glitch.
	const load_model = async function () {
		const div_classes = demosSection.classList;
		if (model) {
			console.log('Model is already loaded!');
			return;
		}
		model = await W.cocoSsd.load();
		
		if (div_classes.contains('invisible'))
			div_classes.remove('invisible');
	};
	load_model();
	// cocoSsd.load().then(function (loadedModel) {
	// 	model = loadedModel;
	// 	// Show demo section now model is ready to use.
	// 	demosSection.classList.remove('invisible');
	// });

	var children = [];

	function predictWebcam() {
		if (!model)
			load_model();
		
		// Now let's start classifying a frame in the stream.
		model.detect(video).then(function (predictions) {
			// Remove any highlighting we did previous frame.
			for (let i = 0; i < children.length; i++) {
				liveView.removeChild(children[i]);
			}
			children.splice(0);
			
			// Now lets loop through predictions and draw them to the live view if
			// they have a high confidence score.
			for (let n = 0; n < predictions.length; n++) {
				// If we are over 66% sure we are sure we classified it right, draw it!
				if (predictions[n].score > 0.66) {
					const p = document.createElement('p');
					p.innerText = predictions[n].class  + ' - with ' 
						+ Math.round(parseFloat(predictions[n].score) * 100) 
						+ '% confidence.';
					p.style = 'margin-left: ' + predictions[n].bbox[0] + 'px; margin-top: '
						+ (predictions[n].bbox[1] - 10) + 'px; width: ' 
						+ (predictions[n].bbox[2] - 10) + 'px; top: 0; left: 0;';

					const highlighter = document.createElement('div');
					highlighter.setAttribute('class', 'highlighter');
					highlighter.style = 'left: ' + predictions[n].bbox[0] + 'px; top: '
						+ predictions[n].bbox[1] + 'px; width: ' 
						+ predictions[n].bbox[2] + 'px; height: '
						+ predictions[n].bbox[3] + 'px;';

					liveView.appendChild(highlighter);
					liveView.appendChild(p);
					children.push(highlighter);
					children.push(p);
				}
			}
			
			// Call this function again to keep predicting when the browser is ready.
			window.requestAnimationFrame(predictWebcam);
		});
	}

</script>